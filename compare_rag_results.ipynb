{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus only on common files\n",
    "# fn to compare file name in common_files to section name\n",
    "# if match, add a field to file called match_name and fill it with 1\n",
    "# if not match, add a field to file called match_name and fill it with 0\n",
    "# structure of comparison\n",
    "# {\"section_name\" : {\"match_name\" : 1/0, \"score\" : 0.0}}\n",
    "# score is the score of the file in the section\n",
    "# compare the match_name field between two dicts\n",
    "# if match_name is 1 then compare the score field\n",
    "# if score is equal then add a field called model and fill it with the model name\n",
    "# if score is not equal then add a field called model and fill it with the model name of the file with the highest score\n",
    "# count each of model name (unique values)\n",
    "# the one with higher count is more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(data):\n",
    "    # remove the only_one_model key from each section since its empty anyway\n",
    "    for section in data:\n",
    "        del data[section][\"only_one_model\"]\n",
    "    # convert each list in the common_files key to a key, value pair\n",
    "    for key in data.keys():\n",
    "        data[key] = {file[0]: file[1] for file in data[key][\"common_files\"]}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for section in list of sections\n",
    "# for file name in section\n",
    "# remove suffix \".php\" \n",
    "# if section name == file name\n",
    "# add a field called retrieved and fill it with 1\n",
    "# add a field called score and fill it with the score\n",
    "# if section name != file name\n",
    "# add a field called retrieved and fill it with 0\n",
    "# add a field called score and fill it with the 0.0\n",
    "def create_eval_dict(data):\n",
    "    eval = {}\n",
    "    for section in data:\n",
    "        eval[section] = {}\n",
    "        target_file = section + \".php\"\n",
    "        if target_file in data[section].keys():\n",
    "            eval[section][\"retrieved\"] = 1\n",
    "            eval[section][\"score\"] = data[section][target_file]\n",
    "        else:\n",
    "            eval[section][\"retrieved\"] = 0\n",
    "            eval[section][\"score\"] = 0.0\n",
    "    return eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_df(data):\n",
    "    # convert result dictionary into a dataframe with section names, files names, and scores as columns\n",
    "    data_df = pd.DataFrame([\n",
    "        {\"section_name\": section, \"retrieved\": metrics[\"retrieved\"], \"score\": metrics[\"score\"]}\n",
    "        for section, metrics in data.items()\n",
    "    ])\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieve_accuracy(eval_df):\n",
    "    ones_count = int(eval_df[eval_df[\"retrieved\"] == 1][\"retrieved\"].value_counts().iloc[0])\n",
    "    print(f\"Count of ones: {ones_count}\")\n",
    "    row_count = eval_df.shape[0]\n",
    "    print(f\"Count total observations: {row_count}\")\n",
    "    return ones_count / row_count * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of ones: 42\n",
      "Count total observations: 69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60.86956521739131"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_data = read_json_file(\"section_result_openai_embeddings.json\")\n",
    "openai_data = post_process(openai_data)\n",
    "openai_eval = create_eval_dict(openai_data)\n",
    "openai_eval_df = convert_dict_df(openai_eval)\n",
    "openai_retrieve_accuracy = get_retrieve_accuracy(openai_eval_df)\n",
    "openai_retrieve_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of ones: 45\n",
      "Count total observations: 69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65.21739130434783"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_specter_data = read_json_file(\"section_result_azure_embeddings.json\")\n",
    "ada_specter_data = post_process(ada_specter_data)\n",
    "ada_specter_eval = create_eval_dict(ada_specter_data)\n",
    "ada_specter_eval_df = convert_dict_df(ada_specter_eval)\n",
    "ada_specter_retrieve_accuracy = get_retrieve_accuracy(ada_specter_eval_df)\n",
    "ada_specter_retrieve_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of ones: 46\n",
      "Count total observations: 69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.66666666666666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_3_specter_data = read_json_file(\"section_result_text_embeddings_large_3.json\")\n",
    "large_3_specter_data = post_process(large_3_specter_data)\n",
    "large_3_specter_eval = create_eval_dict(large_3_specter_data)\n",
    "large_3_specter_eval_df = convert_dict_df(large_3_specter_eval)\n",
    "large_3_specter_retrieve_accuracy = get_retrieve_accuracy(large_3_specter_eval_df)\n",
    "large_3_specter_retrieve_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m large_3_eval \u001b[38;5;241m=\u001b[39m create_eval_dict(large_3_data)\n\u001b[1;32m      4\u001b[0m large_3_eval_df \u001b[38;5;241m=\u001b[39m convert_dict_df(large_3_eval)\n\u001b[0;32m----> 5\u001b[0m large_3_retrieve_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mget_retrieve_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlarge_3_eval_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m large_3_retrieve_accuracy\n",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m, in \u001b[0;36mget_retrieve_accuracy\u001b[0;34m(eval_df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_retrieve_accuracy\u001b[39m(eval_df):\n\u001b[0;32m----> 2\u001b[0m     ones_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43meval_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43meval_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mretrieved\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mretrieved\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount of ones: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mones_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     row_count \u001b[38;5;241m=\u001b[39m eval_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/mnt/d/Protostars/RAG-for-code-analysis/venv/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Protostars/RAG-for-code-analysis/venv/lib/python3.12/site-packages/pandas/core/indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/mnt/d/Protostars/RAG-for-code-analysis/venv/lib/python3.12/site-packages/pandas/core/indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "large_3_data = read_json_file(\"section_result_text_embeddings_large_3_only.json\")\n",
    "large_3_data = post_process(large_3_data)\n",
    "large_3_eval = create_eval_dict(large_3_data)\n",
    "large_3_eval_df = convert_dict_df(large_3_eval)\n",
    "large_3_retrieve_accuracy = get_retrieve_accuracy(large_3_eval_df)\n",
    "large_3_retrieve_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
